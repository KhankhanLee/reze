# Ollama ì„¤ì¹˜ ë° ì‚¬ìš© ê°€ì´ë“œ | Ollama Installation & Usage Guide

Ollamaë¥¼ ì‚¬ìš©í•˜ë©´ ë¡œì»¬ì—ì„œ ê°•ë ¥í•œ LLM ëª¨ë¸ì„ ì‰½ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
Use Ollama to easily run powerful LLM models locally.

---

## ğŸš€ ì„¤ì¹˜ | Installation

### macOS / Linux
```bash
# Homebrewë¡œ ì„¤ì¹˜ (ì¶”ì²œ)
brew install ollama

# ë˜ëŠ” ê³µì‹ ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš©
curl -fsSL https://ollama.com/install.sh | sh
```

### Windows
[Ollama ê³µì‹ ì›¹ì‚¬ì´íŠ¸](https://ollama.com/download)ì—ì„œ ì„¤ì¹˜ í”„ë¡œê·¸ë¨ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.

---

## ğŸ“¦ ì¶”ì²œ ëª¨ë¸ | Recommended Models

### 1ï¸âƒ£ Llama 3.2 1B (ê°€ì¥ ì¶”ì²œ!)
- **í¬ê¸°**: ~1.3GB
- **ì†ë„**: ë§¤ìš° ë¹ ë¦„
- **í’ˆì§ˆ**: LaMini-77Më³´ë‹¤ ì›”ë“±íˆ ìš°ìˆ˜
- **ì„¤ì¹˜**:
```bash
ollama pull llama3.2:1b
```

### 2ï¸âƒ£ Qwen2.5 0.5B
- **í¬ê¸°**: ~0.5GB
- **ì†ë„**: ì´ˆê³ ì†
- **í’ˆì§ˆ**: ì‘ì§€ë§Œ íš¨ìœ¨ì 
- **ì„¤ì¹˜**:
```bash
ollama pull qwen2.5:0.5b
```

### 3ï¸âƒ£ Llama 3.2 3B (ê°•ë ¥í•¨)
- **í¬ê¸°**: ~3GB
- **ì†ë„**: ë¹ ë¦„
- **í’ˆì§ˆ**: ë§¤ìš° ìš°ìˆ˜
- **ì„¤ì¹˜**:
```bash
ollama pull llama3.2:3b
```

---

## âš™ï¸ Ollama ì‹¤í–‰ | Running Ollama

### 1. Ollama ì„œë²„ ì‹œì‘
```bash
# ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì‹¤í–‰
ollama serve
```

### 2. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
```bash
# Llama 3.2 1B ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì¶”ì²œ)
ollama pull llama3.2:1b
```

### 3. í…ŒìŠ¤íŠ¸
```bash
# ëª¨ë¸ì´ ì œëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸
ollama run llama3.2:1b "Hello, introduce yourself briefly"
```

### 4. Reze ì•± ì‹¤í–‰
```bash
# Reze í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ
npm start
```

---

## ğŸ¯ Rezeì—ì„œ ì‚¬ìš©í•˜ê¸° | Using in Reze

### ìë™ ê°ì§€ | Auto Detection
- RezeëŠ” ì‹œì‘ ì‹œ ìë™ìœ¼ë¡œ Ollamaë¥¼ ê°ì§€í•©ë‹ˆë‹¤
- Ollamaê°€ ì‹¤í–‰ ì¤‘ì´ê³  ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤
- Ollamaê°€ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ transformers.jsë¡œ í´ë°±ë©ë‹ˆë‹¤

### ë¡œê·¸ í™•ì¸ | Check Logs
ë¸Œë¼ìš°ì € ì½˜ì†”ì—ì„œ ë‹¤ìŒ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”:
```
âœ“ Ollama is available! Using Ollama for local inference.
Available Ollama models: llama3.2:1b
```

### ëª¨ë¸ ì „í™˜ | Switch Models
ë¸Œë¼ìš°ì € ì½˜ì†”ì—ì„œ:
```javascript
// Ollama ëª¨ë¸ ë³€ê²½
await rezeAI.setOllamaModel('llama3.2:3b');

// í´ë¼ìš°ë“œ APIë¡œ ì „í™˜
await rezeAI.switchProvider('gemini');

// ë¡œì»¬ë¡œ ë‹¤ì‹œ ì „í™˜
await rezeAI.switchProvider('local');
```

---

## ğŸ”§ ë¬¸ì œ í•´ê²° | Troubleshooting

### Ollama ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ
```bash
# Ollama ìƒíƒœ í™•ì¸
ps aux | grep ollama

# Ollama ë‹¤ì‹œ ì‹œì‘
killall ollama
ollama serve
```

### ëª¨ë¸ì´ ë‹¤ìš´ë¡œë“œë˜ì§€ ì•ŠìŒ
```bash
# ì„¤ì¹˜ëœ ëª¨ë¸ ëª©ë¡ í™•ì¸
ollama list

# ëª¨ë¸ ë‹¤ì‹œ ë‹¤ìš´ë¡œë“œ
ollama pull llama3.2:1b
```

### "Ollama not available" ë©”ì‹œì§€
1. Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸: `which ollama`
2. Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸: `ollama serve`
3. ë°©í™”ë²½ì—ì„œ í¬íŠ¸ 11434ê°€ ì—´ë ¤ìˆëŠ”ì§€ í™•ì¸

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ | Performance Comparison

| ëª¨ë¸ | í¬ê¸° | í’ˆì§ˆ | ì†ë„ | ì¶”ì²œ |
|------|------|------|------|------|
| LaMini-Flan-T5-77M | 300MB | â­â­ | â­â­â­â­ | âŒ |
| Qwen2.5 0.5B | 500MB | â­â­â­â­ | â­â­â­â­â­ | âœ… |
| Llama 3.2 1B | 1.3GB | â­â­â­â­â­ | â­â­â­â­ | â­ ìµœê³  ì¶”ì²œ |
| Llama 3.2 3B | 3GB | â­â­â­â­â­ | â­â­â­ | âœ… |

---

## ğŸ’¡ íŒ | Tips

### 1. ìë™ ì‹œì‘ ì„¤ì •
macOSì—ì„œ Ollamaë¥¼ ìë™ìœ¼ë¡œ ì‹œì‘í•˜ë ¤ë©´:
```bash
# LaunchAgent ìƒì„±
cat > ~/Library/LaunchAgents/com.ollama.server.plist << EOF
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
    <key>Label</key>
    <string>com.ollama.server</string>
    <key>ProgramArguments</key>
    <array>
        <string>/opt/homebrew/bin/ollama</string>
        <string>serve</string>
    </array>
    <key>RunAtLoad</key>
    <true/>
    <key>KeepAlive</key>
    <true/>
</dict>
</plist>
EOF

# LaunchAgent ë¡œë“œ
launchctl load ~/Library/LaunchAgents/com.ollama.server.plist
```

### 2. ì—¬ëŸ¬ ëª¨ë¸ ì„¤ì¹˜
ë‹¤ì–‘í•œ ìƒí™©ì— ë§ëŠ” ëª¨ë¸ì„ ì¤€ë¹„í•˜ì„¸ìš”:
```bash
# ë¹ ë¥¸ ì‘ë‹µìš©
ollama pull qwen2.5:0.5b

# ì¼ë°˜ì ì¸ ëŒ€í™”ìš©
ollama pull llama3.2:1b

# ë³µì¡í•œ ì‘ì—…ìš©
ollama pull llama3.2:3b
```

### 3. GPU ê°€ì†
- OllamaëŠ” ìë™ìœ¼ë¡œ GPUë¥¼ ê°ì§€í•˜ê³  ì‚¬ìš©í•©ë‹ˆë‹¤
- Apple Silicon (M1/M2/M3): Metal ìë™ í™œì„±í™”
- NVIDIA GPU: CUDA ìë™ í™œì„±í™”

---

## ğŸ”— ì°¸ê³  ë§í¬ | References

- [Ollama ê³µì‹ ì›¹ì‚¬ì´íŠ¸](https://ollama.com)
- [Ollama GitHub](https://github.com/ollama/ollama)
- [ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡](https://ollama.com/library)

---

## ğŸ‰ ì‹œì‘í•˜ê¸° | Get Started

```bash
# 1. Ollama ì„¤ì¹˜
brew install ollama

# 2. Ollama ì„œë²„ ì‹œì‘
ollama serve &

# 3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
ollama pull llama3.2:1b

# 4. Reze ì‹¤í–‰
cd /path/to/reze
npm start

# 5. ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:8081 ì ‘ì†
```

ì´ì œ Ollamaë¡œ í›¨ì”¬ ë” ìì—°ìŠ¤ëŸ¬ìš´ Rezeì™€ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ’£ğŸŒ™
